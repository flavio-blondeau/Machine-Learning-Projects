{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.activations import Linear, Sigmoid, Tanh, ReLU\n",
    "from utils.layers import Dense\n",
    "from utils.losses import MeanSquaredError, Softmax\n",
    "from utils.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from utils.network import NeuralNetwork\n",
    "from utils.train import Trainer\n",
    "from utils.utility_functions import softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST dataset - Credit: https://github.com/hsjeong5\n",
    "\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "\n",
    "def download_mnist():\n",
    "  base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "  for name in filename:\n",
    "    print(\"Downloading \"+name[1]+\"...\")\n",
    "    request.urlretrieve(base_url+name[1], name[1])\n",
    "  print(\"Download complete.\")\n",
    "\n",
    "\n",
    "def save_mnist():\n",
    "  mnist = {}\n",
    "  for name in filename[:2]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "      mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "  for name in filename[-2:]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "      mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "  with open(\"mnist.pkl\", 'wb') as f:\n",
    "    pickle.dump(mnist,f)\n",
    "  print(\"Save complete.\")\n",
    "\n",
    "\n",
    "def init():\n",
    "  download_mnist()\n",
    "  save_mnist()\n",
    "\n",
    "\n",
    "def load():\n",
    "  with open(\"mnist.pkl\",'rb') as f:\n",
    "    mnist = pickle.load(f)\n",
    "  return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load()\n",
    "num_labels = len(y_train)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding labels (both train and test)\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "  train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "  test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (mean 0, variance 1)\n",
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)\n",
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for accuracy\n",
    "def calc_accuracy_model(model, test_set):\n",
    "        return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.936.\n",
      "Validation loss after 20 epochs is 0.932.\n",
      "Validation loss after 30 epochs is 0.931.\n",
      "\n",
      "Loss increased after epoch 40, the final loss was 0.931, using the model from epoch 30\n",
      "\n",
      "The model validation accuracy is: 44.10%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Tanh()),\n",
    "              Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = MeanSquaredError(normalize=True),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGD(learning_rate = 0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.603.\n",
      "Validation loss after 20 epochs is 0.523.\n",
      "Validation loss after 30 epochs is 0.491.\n",
      "Validation loss after 40 epochs is 0.472.\n",
      "Validation loss after 50 epochs is 0.465.\n",
      "\n",
      "The model validation accuracy is: 92.11%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGD(learning_rate = 0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax loss function works way better than MSE! Now we try to use ReLU or Tanh activations with Softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\activations.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-1.0 * self.input_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2.462.\n",
      "Validation loss after 20 epochs is 2.426.\n",
      "Validation loss after 30 epochs is 2.406.\n",
      "Validation loss after 40 epochs is 2.396.\n",
      "Validation loss after 50 epochs is 2.392.\n",
      "\n",
      "The model validation accuracy is: 86.81%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=ReLU()),\n",
    "              Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGD(learning_rate = 0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.627.\n",
      "Validation loss after 20 epochs is 0.564.\n",
      "Validation loss after 30 epochs is 0.551.\n",
      "Validation loss after 40 epochs is 0.543.\n",
      "\n",
      "Loss increased after epoch 50, the final loss was 0.543, using the model from epoch 40\n",
      "\n",
      "The model validation accuracy is: 90.99%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Tanh()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGD(learning_rate = 0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, using Softmax as loss, Sigmoid and Tanh are the best activations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.362.\n",
      "\n",
      "Loss increased after epoch 20, the final loss was 0.362, using the model from epoch 10\n",
      "\n",
      "The model validation accuracy is: 94.39%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(learning_rate = 0.1, momentum = 0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, adding momentum in the parameters update rule make the accuracy better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.364.\n",
      "\n",
      "Loss increased after epoch 20, the final loss was 0.364, using the model from epoch 10\n",
      "\n",
      "The model validation accuracy is: 94.35%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(learning_rate = 0.1, momentum = 0.9, final_lr = 0.05, decay_type = 'linear'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.363.\n",
      "\n",
      "Loss increased after epoch 20, the final loss was 0.363, using the model from epoch 10\n",
      "\n",
      "The model validation accuracy is: 94.24%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(learning_rate = 0.1, momentum = 0.9, final_lr = 0.05, decay_type = 'exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that in our case weight decay does not improve the model accuracy (but in general it is a good practice)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.144.\n",
      "Validation loss after 20 epochs is 0.137.\n",
      "\n",
      "Loss increased after epoch 30, the final loss was 0.137, using the model from epoch 20\n",
      "\n",
      "The model validation accuracy is: 97.75%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid(), weight_init='glorot'),\n",
    "              Dense(neurons=10, activation=Linear(), weight_init='glorot')],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(learning_rate = 0.1, momentum = 0.9, final_lr = 0.05, decay_type = 'linear'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Accuracy has increased!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.147.\n",
      "Validation loss after 20 epochs is 0.143.\n",
      "\n",
      "Loss increased after epoch 30, the final loss was 0.143, using the model from epoch 20\n",
      "\n",
      "The model validation accuracy is: 97.69%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Dense(neurons=89, activation=Sigmoid(), weight_init='glorot', dropout=0.8),\n",
    "              Dense(neurons=10, activation=Linear(), weight_init='glorot')],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(learning_rate = 0.1, momentum = 0.9, final_lr = 0.05, decay_type = 'linear'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too useful here. Let's test with another model, first without dropout and then with dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.164.\n",
      "Validation loss after 20 epochs is 0.160.\n",
      "\n",
      "Loss increased after epoch 30, the final loss was 0.160, using the model from epoch 20\n",
      "\n",
      "The model validation accuracy is: 97.95%\n"
     ]
    }
   ],
   "source": [
    "model2 = NeuralNetwork(\n",
    "    layers = [Dense(neurons=178, activation=Sigmoid(), weight_init='glorot'),\n",
    "              Dense(neurons=46, activation=Sigmoid(), weight_init='glorot'),\n",
    "              Dense(neurons=10, activation=Linear(), weight_init='glorot')],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(model2, SGDMomentum(learning_rate = 0.2, momentum = 0.9, final_lr = 0.05, decay_type = 'exponential'))\n",
    "trainer2.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 100, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model2, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.154.\n",
      "Validation loss after 20 epochs is 0.140.\n",
      "\n",
      "Loss increased after epoch 30, the final loss was 0.140, using the model from epoch 20\n",
      "\n",
      "The model validation accuracy is: 97.89%\n"
     ]
    }
   ],
   "source": [
    "model2 = NeuralNetwork(\n",
    "    layers = [Dense(neurons=178, activation=Sigmoid(), weight_init='glorot', dropout=0.8),\n",
    "              Dense(neurons=46, activation=Sigmoid(), weight_init='glorot', dropout=0.8),\n",
    "              Dense(neurons=10, activation=Linear(), weight_init='glorot')],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(model2, SGDMomentum(learning_rate = 0.2, momentum = 0.9, final_lr = 0.05, decay_type = 'exponential'))\n",
    "trainer2.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 100, eval_every = 10, seed = 42, batch_size = 60)\n",
    "print()\n",
    "calc_accuracy_model(model2, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9ba51474155098adcf5d6ec0d5cb5aad37ed0d1c717711478d35ffc4f517c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
