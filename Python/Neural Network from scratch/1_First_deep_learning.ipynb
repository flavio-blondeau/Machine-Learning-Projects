{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.activations import Linear, Sigmoid, Tanh, ReLU\n",
    "from utils.layers import Dense\n",
    "from utils.losses import MeanSquaredError\n",
    "from utils.network import NeuralNetwork\n",
    "from utils.optimizers import SGD\n",
    "from utils.train import Trainer\n",
    "from utils.utility_functions import to_2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maen Absolute Error\n",
    "def mae(y_true: np.ndarray, y_pred: np.ndarray):    \n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "def rmse(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.sqrt(np.mean(np.power(y_true - y_pred, 2)))\n",
    "\n",
    "# Compute MAE and RMSE for a NN\n",
    "def eval_regression_model(model: NeuralNetwork, X_test: np.ndarray, y_test: np.ndarray):\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds.reshape(-1, 1)\n",
    "    print(\"Mean absolute error: {:.2f}\".format(mae(preds, y_test)))\n",
    "    print(\"\\nRoot mean squared error {:.2f}\".format(rmse(preds, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define three kinds of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer nn (aka linear regression)\n",
    "linear_regression = NeuralNetwork(\n",
    "    layers = [Dense(neurons = 1, activation = Linear())],\n",
    "    loss = MeanSquaredError(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "# 2 layer nn\n",
    "nn = NeuralNetwork(\n",
    "    layers = [Dense(neurons = 13, activation = Sigmoid()),\n",
    "              Dense(neurons = 1, activation = Linear())],\n",
    "    loss = MeanSquaredError(),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "# 3 layer nn\n",
    "deep_nn = NeuralNetwork(\n",
    "    layers = [Dense(neurons = 13, activation = Sigmoid()),\n",
    "              Dense(13, activation = Sigmoid()),\n",
    "              Dense(1, activation = Linear())],\n",
    "    loss = MeanSquaredError(),\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test and make targets 2D arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "y_train, y_test = to_2d(y_train), to_2d(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 37.226.\n",
      "Validation loss after 20 epochs is 29.312.\n",
      "Validation loss after 30 epochs is 26.731.\n",
      "Validation loss after 40 epochs is 26.571.\n",
      "\n",
      "Loss increased after epoch 50, the final loss was 26.571, using the model from epoch 40\n",
      "\n",
      "Mean absolute error: 3.68\n",
      "\n",
      "Root mean squared error 5.20\n"
     ]
    }
   ],
   "source": [
    "# Train linear regression\n",
    "trainer = Trainer(linear_regression, SGD(learning_rate = 0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test, epochs = 50, eval_every = 10, seed = 42);\n",
    "print()\n",
    "eval_regression_model(linear_regression, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 35.272.\n",
      "Validation loss after 20 epochs is 20.043.\n",
      "Validation loss after 30 epochs is 17.688.\n",
      "Validation loss after 40 epochs is 15.706.\n",
      "Validation loss after 50 epochs is 14.666.\n",
      "\n",
      "Mean absolute error: 2.53\n",
      "\n",
      "Root mean squared error 3.83\n"
     ]
    }
   ],
   "source": [
    "# Train 2 layers nn\n",
    "trainer = Trainer(nn, SGD(learning_rate = 0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test, epochs = 50, eval_every = 10, seed = 42)\n",
    "print()\n",
    "eval_regression_model(nn, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are significantly better than the straightforward linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 89.403.\n",
      "Validation loss after 20 epochs is 19.193.\n",
      "Validation loss after 30 epochs is 16.681.\n",
      "Validation loss after 40 epochs is 14.424.\n",
      "Validation loss after 50 epochs is 12.989.\n",
      "\n",
      "Mean absolute error: 2.37\n",
      "\n",
      "Root mean squared error 3.60\n"
     ]
    }
   ],
   "source": [
    "# Train 3 layers nn\n",
    "trainer = Trainer(deep_nn, SGD(learning_rate = 0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test, epochs = 50, eval_every = 10, seed = 42);\n",
    "print()\n",
    "eval_regression_model(deep_nn, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this first attempt of deep learning, our model performs slightly better than a simple neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9ba51474155098adcf5d6ec0d5cb5aad37ed0d1c717711478d35ffc4f517c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
