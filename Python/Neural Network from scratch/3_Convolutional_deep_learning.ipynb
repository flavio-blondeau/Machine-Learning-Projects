{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.layers import Dense, Conv2D\n",
    "from utils.losses import Softmax, MeanSquaredError\n",
    "from utils.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from utils.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from utils.network import NeuralNetwork\n",
    "from utils.train import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST dataset - Credit: https://github.com/hsjeong5\n",
    "\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "\n",
    "def download_mnist():\n",
    "  base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "  for name in filename:\n",
    "    print(\"Downloading \"+name[1]+\"...\")\n",
    "    request.urlretrieve(base_url+name[1], name[1])\n",
    "  print(\"Download complete.\")\n",
    "\n",
    "\n",
    "def save_mnist():\n",
    "  mnist = {}\n",
    "  for name in filename[:2]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "      mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "  for name in filename[-2:]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "      mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "  with open(\"mnist.pkl\", 'wb') as f:\n",
    "    pickle.dump(mnist,f)\n",
    "  print(\"Save complete.\")\n",
    "\n",
    "\n",
    "def init():\n",
    "  download_mnist()\n",
    "  save_mnist()\n",
    "\n",
    "\n",
    "def load():\n",
    "  with open(\"mnist.pkl\",'rb') as f:\n",
    "    mnist = pickle.load(f)\n",
    "  return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (mean 0, variance 1)\n",
    "X_train, y_train, X_test, y_test = load()\n",
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)\n",
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv, X_test_conv = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding labels (both train and test)\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "  train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "  test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for accuracy\n",
    "def calc_accuracy_model(model, test_set):\n",
    "        return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers = [Conv2D(out_channels=16, param_size=5, dropout=0.8, weight_init=\"glorot\", flatten=True, activation=Tanh()),\n",
    "              Dense(neurons=10, activation=Linear())],\n",
    "    loss = Softmax(),\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\3_Convolutional_deep_learning.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Flavio/Desktop/Data%20Science/Neural%20Network%20from%20scratch/3_Convolutional_deep_learning.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, SGDMomentum(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Flavio/Desktop/Data%20Science/Neural%20Network%20from%20scratch/3_Convolutional_deep_learning.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(X_train_conv, train_labels, X_test_conv, test_labels, epochs \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, eval_every \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, seed \u001b[39m=\u001b[39;49m \u001b[39m42\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m60\u001b[39;49m, conv_testing \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m);\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\train.py:56\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, X_train, y_train, X_test, y_test, epochs, eval_every, batch_size, seed, single_output, restart, early_stopping, conv_testing)\u001b[0m\n\u001b[0;32m     53\u001b[0m batch_generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_batches(X_train, y_train, batch_size)\n\u001b[0;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m j, (X_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch_generator):\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet\u001b[39m.\u001b[39;49mtrain_batch(X_batch, y_batch)\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m conv_testing:\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\network.py:72\u001b[0m, in \u001b[0;36mNeuralNetwork.train_batch\u001b[1;34m(self, X_batch, y_batch, inference)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_batch\u001b[39m(\u001b[39mself\u001b[39m, X_batch: np\u001b[39m.\u001b[39mndarray, y_batch: np\u001b[39m.\u001b[39mndarray, inference: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m---> 72\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(X_batch, inference)\n\u001b[0;32m     74\u001b[0m     batch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mforward(prediction, y_batch)\n\u001b[0;32m     75\u001b[0m     loss_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\network.py:17\u001b[0m, in \u001b[0;36mLayerBlock.forward\u001b[1;34m(self, X_batch, inference)\u001b[0m\n\u001b[0;32m     15\u001b[0m X_out \u001b[39m=\u001b[39m X_batch\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 17\u001b[0m     X_out \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(X_out, inference)\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m X_out\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\layers.py:43\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, input_, inference)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m# Perform the operations\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m operation \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moperations:\n\u001b[1;32m---> 43\u001b[0m     input_ \u001b[39m=\u001b[39m operation\u001b[39m.\u001b[39;49mforward(input_, inference)\n\u001b[0;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m input_\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\basics.py:17\u001b[0m, in \u001b[0;36mOperation.forward\u001b[1;34m(self, input_, inference)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_: np\u001b[39m.\u001b[39mndarray, inference: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_ \u001b[39m=\u001b[39m input_\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output(inference)\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:55\u001b[0m, in \u001b[0;36mConv2D_Op._output\u001b[1;34m(self, inference)\u001b[0m\n\u001b[0;32m     52\u001b[0m img_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]\n\u001b[0;32m     53\u001b[0m patch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]\n\u001b[1;32m---> 55\u001b[0m patches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_image_patches(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_)\n\u001b[0;32m     57\u001b[0m patches_reshape \u001b[39m=\u001b[39m (patches\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mreshape(batch_size, img_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     59\u001b[0m param_reshape \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(patch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:37\u001b[0m, in \u001b[0;36mConv2D_Op._get_image_patches\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_image_patches\u001b[39m(\u001b[39mself\u001b[39m, input_: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 37\u001b[0m     img_batch_pad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pad_2d_channel(obs) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m input_])\n\u001b[0;32m     39\u001b[0m     patches \u001b[39m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m     img_height \u001b[39m=\u001b[39m img_batch_pad\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:37\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_image_patches\u001b[39m(\u001b[39mself\u001b[39m, input_: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 37\u001b[0m     img_batch_pad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pad_2d_channel(obs) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m input_])\n\u001b[0;32m     39\u001b[0m     patches \u001b[39m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m     img_height \u001b[39m=\u001b[39m img_batch_pad\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:33\u001b[0m, in \u001b[0;36mConv2D_Op._pad_2d_channel\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pad_2d_channel\u001b[39m(\u001b[39mself\u001b[39m, inp: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     32\u001b[0m     \u001b[39m# inp dimensions are (num_channels, image_width, image_height)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pad_2d_obs(channel \u001b[39mfor\u001b[39;49;00m channel \u001b[39min\u001b[39;49;00m inp)])\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:26\u001b[0m, in \u001b[0;36mConv2D_Op._pad_2d_obs\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pad_2d_obs\u001b[39m(\u001b[39mself\u001b[39m, inp: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 26\u001b[0m     inp_pad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pad_1d_batch(inp)\n\u001b[0;32m     27\u001b[0m     other \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_pad, inp\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_pad\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([other, inp_pad, other])\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:21\u001b[0m, in \u001b[0;36mConv2D_Op._pad_1d_batch\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pad_1d_batch\u001b[39m(\u001b[39mself\u001b[39m, inp: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 21\u001b[0m     outs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pad_1d(obs) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m inp]\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mstack(outs)\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pad_1d_batch\u001b[39m(\u001b[39mself\u001b[39m, inp: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 21\u001b[0m     outs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pad_1d(obs) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m inp]\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mstack(outs)\n",
      "File \u001b[1;32mc:\\Users\\Flavio\\Desktop\\Data Science\\Neural Network from scratch\\utils\\convolution.py:17\u001b[0m, in \u001b[0;36mConv2D_Op._pad_1d\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     15\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m])\n\u001b[0;32m     16\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(z, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_pad)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mconcatenate([z, inp, z])\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, SGDMomentum(learning_rate=0.1, momentum=0.9))\n",
    "trainer.fit(X_train_conv, train_labels, X_test_conv, test_labels, epochs = 1, eval_every = 1, seed = 42, batch_size = 60, conv_testing = True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
